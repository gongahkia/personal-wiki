# `Using LLMs For Code`

How to use Large Language Models to help write code, based on an article by Simon Willison.

## Core Principles

* **Set reasonable expectations**: Treat LLMs as a "fancy autocomplete" or an "over-confident pair programming assistant". They augment your abilities, but will make mistakes.
* **Account for training cut-off dates**: Be aware of the model's knowledge cut-off date, as it won't be aware of newer libraries or breaking changes. Stick to stable, popular libraries when possible.
* **Context is king**: The quality of the output depends on the context provided. This includes the entire conversation history. Start new chats to reset context when needed. Provide examples of code to guide the model.
* **Ask for options**: Use LLMs for initial research to explore possibilities and different ways to implement a feature.
* **Tell them exactly what to do**: Be authoritarian and provide detailed instructions, including function signatures. This is often faster than writing the code yourself.
* **You have to test what it writes**: You are still responsible for delivering working software. Always test the code generated by the LLM.
* **Remember it’s a conversation**: Don't accept the first output. Refactor, ask for changes, and iterate until you get the desired result.
* **Use tools that can run the code for you**: Tools that can execute the generated code in a loop (like ChatGPT Code Interpreter or Claude Code) are powerful for iteration.
* **"Vibe-coding" is a great way to learn**: For non-critical projects, embracing a rapid, less-critical approach can be a fun and effective way to build intuition for what works.
* **Be ready for the human to take over**: LLMs are not a replacement for human experience. Know when to step in and solve a problem yourself.

## Key Advantages

* **Speed of development**: LLMs allow you to ship projects that might otherwise not be worth the time investment.
* **Amplify existing expertise**: Your experience is crucial for effective prompting and for knowing what's possible.
* **Answering questions about codebases**: LLMs are great for getting a quick architectural overview of a new codebase.

## Resources

* [Here’s how I use LLMs to help me write code](https://simonwillison.net/2025/Mar/11/using-llms-for-code/) - The original article by Simon Willison.
* [JavaScript OCR application that combines Tesseract.js and PDF.js](https://simonwillison.net/2023/Oct/26/ocr-is-a-solved-problem/)
* [Everything I built with Claude Artifacts this week](https://simonwillison.net/2023/Oct/23/claude-artifacts/)
* [tools.simonwillison.net](https://tools.simonwillison.net/) - Simon Willison's collection of LLM-built tools.
* [Colophon for the tools](https://tools.simonwillison.net/colophon)
* [Using custom workflows with GitHub Pages](https://docs.github.com/en/pages/getting-started-with-github-pages/configuring-a-publishing-source-for-your-github-pages-site#using-a-custom-github-actions-workflow)
* [monolith](https://github.com/Y2Z/monolith) - CLI tool to bundle a web page into a single file.
* [files-to-prompt](https://github.com/simonw/files-to-prompt)
* [LLM tool](https://llm.datasette.io/)
* [llm-gemini plugin](https://github.com/simonw/llm-gemini)
