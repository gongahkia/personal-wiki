<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="Wiki Note: Scrapy - Gabriel Ong">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="Gabriel Ong">
  <meta name="robots" content="index, follow">
  
  <meta property="og:title" content="Scrapy | Gabriel Ong Wiki">
  <meta property="og:description" content="Wiki Note: Scrapy - Gabriel Ong">
  <meta property="og:type" content="article">
  
  <meta property="og:image" content="https://gabrielongzm.com/asset/portrait/gong-2.png">
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Scrapy | Gabriel Ong Wiki">
  <meta name="twitter:description" content="Wiki Note: Scrapy - Gabriel Ong">
  
  <link rel="stylesheet" href="../../style.css">
  <link rel="preload" href="https://res.hajimehoshi.com/fonts/SuisseIntl-Regular-WebXL.woff2" as="font" crossorigin="anonymous">
  
  <link rel="preload" href="https://res.hajimehoshi.com/fonts/SuisseIntlMono-Regular-WebXL.woff2" as="font" crossorigin="anonymous">

  <style>.thin-space:after{content:"\2006"}</style>
  
  <style>pre { overflow-x: auto; max-width: 100%; }</style>

  <script src="../script.js" defer></script>
  <title>GABRIEL ONG</title>
  <link rel="shortcut icon" href="../asset/blob.ico" type="image/x-icon">
</head>
<body>
  <div id="click-container"></div>
  <input type="button" id="dark-mode">
  <label for="dark-mode">
    <img id="infinityButton" src="../asset/roller.png" height="24" width="24"/>
  </label>
  <main>
    <article class="overallArticleTags">
      
      <section class="note-header">
        <h2>Scrapy</h2>
        <dl>
          <dt>File size</dt>
          <dd>9.2KB</dd>
          <dt>Lines of code</dt>
          <dd>133</dd>
        </dl>
      </section>
      <section class="note-content">
        <h1><code>Scrapy</code></h1>
<p>Complete webscraping toolkit.</p>
<h2>Introduction</h2>
<ul>
<li>open-source and collaborative web crawling framework specifically for Python</li>
<li>powerful tool for data mining, automation, and building custom web crawlers</li>
<li>capable of handling large-scale scraping tasks because base is built on Twisted <em>(asynchronous networking framework)</em></li>
<li>extracts website data, processes it, then stores it to the following target outputs<ul>
<li><code>.json</code> <em>(JSON)</em>: lightweight and widely-used data interchange format ideal for web applications and APIs</li>
<li><code>.csv</code> <em>(CSV)</em>: comma-separated values is a simple format used to store tabular data, compatible with applications like Excel, Google Sheets, and most databases</li>
<li><code>.xml</code> <em>(XML)</em>: extensible markup language is a structured format useful for data interchange paritcularly for legacy systems and services</li>
<li><code>.sql</code> <em>(SQL)</em>: structured query language is a descriptive language used to interact with relational databases such as SQLite, MySQL and PostgreSQL</li>
<li><code>.py</code> <em>(Python)</em>: scraped data can be stored in Python's data structures <em>(lists, dictionaries, custom objects)</em> for custom processing </li>
<li>ElasticSearch: a powerful search engine ideal for handling large volumes of data and complex queries</li>
<li>MongoDB: a NoSQL database well-suited for storing unstructured or semi-structured data</li>
<li>Direct API calls: scraped data can be directly piped to a REST API or other service endpoints</li>
</ul>
</li>
</ul>
<h2>Installation</h2>
<div class="codehilite"><pre><span></span><code><span class="gp">$ </span>pip<span class="w"> </span>install<span class="w"> </span>scrapy
</code></pre></div>

<h2>Quickstart</h2>
<p>Create a new scrapy project with the below command.</p>
<div class="codehilite"><pre><span></span><code><span class="gp">$ </span>scrapy<span class="w"> </span>startproject<span class="w"> </span>myproject<span class="w"> </span><span class="c1"># creates a new Scrapy project in the current directory</span>
</code></pre></div>

<p>A spider is a class that defines how to follow links through a website and extract data from its webpages. </p>
<p>The below sample code creates a simple spider that scrapes quotes from the website <a href="http://quotes.toscrape.com/"><em>Quotes to Scrape</em></a>.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">scrapy</span>

<span class="k">class</span><span class="w"> </span><span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes&quot;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://quotes.toscrape.com/&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;small.author::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.tags a.tag::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(href)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre></div>

<p>You can then run your spider with the below command.</p>
<div class="codehilite"><pre><span></span><code><span class="gp">$ </span>scrapy<span class="w"> </span>crawl<span class="w"> </span>quotes<span class="w"> </span>-o<span class="w"> </span>quotes.json<span class="w"> </span><span class="c1"># runs the spider and outputs the scraped data to a quotes.json file</span>
</code></pre></div>

<p>You can further customize your spider within the <code>settings.py</code> file. </p>
<h2>More on</h2>
<ul>
<li><a href="https://scrapy.org/">scrapy.org</a></li>
<li><a href="https://github.com/scrapy/scrapy">scrapy</a> Github repository</li>
<li><a href="https://docs.scrapy.org/en/latest/">Scrapy documentation</a></li>
<li><a href="https://docs.scrapy.org/en/latest/topics/spiders.html">Scrapy Spiders documentation</a></li>
<li><a href="https://scrapy.org/download/">Download Scrapy</a></li>
<li><a href="https://scrapy.org/resources/">Scrapy resources</a></li>
<li><a href="https://youtu.be/mBoX_JCKZTE?si=0CbkuRH5xegUs0zw">Scrapy Course â€“ Python Web Scraping for Beginners</a> by freeCodeCamp.org</li>
<li><a href="https://www.reddit.com/r/webscraping/comments/wypsg4/what_are_your_thoughts_on_scrapy/">What are your thoughts on scrapy</a> by r/webscraping</li>
<li><a href="https://docs.scrapy.org/en/latest/intro/overview.html">Scrapy at a glance</a></li>
<li><a href="https://stackoverflow.com/questions/19687421/difference-between-beautifulsoup-and-scrapy-crawler">Difference between BeautifulSoup and Scrapy crawler?</a> by Stack Overflow</li>
<li><a href="https://hexfox.com/p/scrapy-vs-beautifulsoup/">When should you use Scrapy over BeautifulSoup <em>(...and what's the difference anyway?)</em></a> by Hexfox</li>
<li><a href="https://twisted.org/">twisted.org</a></li>
</ul>
      </section>

    </article>
    <footer>
      <p>&copy; 2023-<span id="current-year"></span> Gabriel Ong. All rights reserved.</p>
    </footer>
  </main>
  <div class="wrapper"></div>
  
</body>
</html>